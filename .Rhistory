min <- round(60*(x%%1));
hrs[min==60] <- (hrs+1)%%24
min[min==60] <- 0
sprintf("%2i:%02i",hrs,min)
}
asTime0 <- function(x){
hrs <- (x%%24)%/%1;
min <- round(60*(x%%1));
hrs[min==60] <- (hrs+1)%%24
min[min==60] <- 0
sprintf("%02i:%02i",hrs,min)
}
#=====================================================================
# new plotting routines
#=====================================================================
timeErrPlot <- function(trueTimes,predTimes,...){
errplot(trueTimes,predTimes,...)
timeDiffs <- timeErr(trueTimes,predTimes)
return(timeDiffs)
}
timeErrSignedPlot <- function(trueTimes,predTimes,...){
errplot(trueTimes,predTimes,...)
timeDiffs <- timeErrSigned(predTimes,trueTimes)
return(timeDiffs)
}
tolplot <- function(trueHr,predHr,add=FALSE,col=1,...){
# plot % correct by tolerance, without lines
predTimes <- predHr%%24
trueTimes <- trueHr%%24
hrerr <- abs(predTimes-trueTimes)
hrerr <- hrerr[!is.na(hrerr)]
hrerr <- pmin(hrerr,24-hrerr)
hrsoff <- seq(0,12,length=49)
fracacc <- sapply(hrsoff,function(hrtol){
100*sum(abs(hrerr)>hrtol)/length(hrerr)
})
if(!add){
col=1
plot(hrsoff,100-fracacc,xlim=c(0,12), type="n",
main="Absolute error CDF", xlab="",ylab="")
mtext("correct to within (hrs)",side=1,line=2.2,cex=0.8)
mtext(paste("% correct (N = ",length(hrerr),")",sep=""),side=2,line=2.4,cex=0.8)
abline(a=0,b=100/12,col="grey")
asTime <- function(x){
hrs <- (x%%24)%/%1;
min <- round(60*(x%%1));
if(min==60){hrs <- (hrs+1)%%24; min<-0}
sprintf("%2i:%02i",hrs,min)
}
}
lines(hrsoff, 100-fracacc, col=col,lwd=1.5,...)
norm.fracacc <- (100-fracacc)/100
norm.hrsoff <- hrsoff/12
auc <- sum(norm.fracacc[-1]*diff(norm.hrsoff))
return(list(auc=auc,mederr=median(abs(hrerr))) )
}
predplot <- function(trueHr,predHr,col=1,pch=1,main="Time of Day (24h)",...){
# do both of the above -- set par(mfrow=c(2,1)) or (1,2) first!
opar <- par(xpd=F,mar=c(4,4,3,1))
on.exit(par(opar))
out <- timeErrPlot(trueHr,predHr,col,pch,main)
out <- tolplot(trueHr,predHr)
invisible(out)
}
#=====================================================================
# Training with Moller subset data
#=====================================================================
# Note - the subset chosen for training is already indicated in
# the data, but we will refresh it here for completeness:
set.seed(194)
trainFrac <- 0.5
moller.char <- all.meta[all.meta$study=="TrTe",]
trainSet <- unique(moller.char$ID)
trainSet <- sample(trainSet,size=round(trainFrac*length(trainSet)),replace=FALSE)
moller.char$train <- as.numeric(moller.char$ID%in%trainSet)
all.meta[all.meta$study=="TrTe","train"] <- moller.char$train
# When fixing the foldid's for opimizing alpha, the following
# randomly-generate foldids were used; we repeat this here too
# for illustration and reproducibility:
train.foldid <- sample(trainSet)
train.foldid <- sample(rep(seq(10),length=sum(moller.char$train)))
trainDat <- all.expr[,all.meta$train==1]
trainSubjs <- all.meta[all.meta$train==1,"ID"]
trainTimes <- all.meta[all.meta$train==1,"LocalTime"]
# within-subject normalization using all timepoints
trainWSN <- recalibrateExprs(trainDat, trainSubjs)
TSorig <- trainTimeStamp(
expr=trainWSN, # use within-subject normalized data
subjIDs=trainSubjs,
times=trainTimes,
trainFrac=1, # no need to subset training samples; already done!
recalib=FALSE, # no need to within-subj normalize; already done!
a=0.5, s=exp(-1.42), # penalty params as used in the paper
foldid=train.foldid, # foldIDs as in the paper
plot=FALSE
)
View(TSorig)
head(predict(TSorig$cv.fit,type="coef"), 20)
P.coef<-(predict(TSorig$cv.fit,type="coef"))
View(P.coef)
P2<-as.data.frame(P.coef[row.names(P.coef), ])
head(predict(TSorig$cv.fit,type="coef"), 20)
head(predict(TSorig$cv.fit,type="coef"), 5)
head(predict(TSorig$cv.fit,type="coef"), 1)
P_x<-as.data.frame(P.coef$timeX[row.names(P.coef$timeX), ])
View(P_x)
P_y<-as.data.frame(P.coef$timeY[row.names(P.coef$timeY), ])
View(P_y)
p_x$genes<-row.names(p_x)
P_x$genes<-row.names(P_x)
P_y$genes<-row.names(P_y)
colnamesP_x<-c('ce', 'genes')
View(P_x)
View(P_y)
head(predict(TSorig$cv.fit,type="coef"), 1)
colnames(P_x)<-c('ce', 'genes')
View(P_x)
Px_sort<-(P_x[order(-P_x$ce),])
View(Px_sort)
P_y$genes<-row.names(P_y)
colnames(P_y)<-c('ce', 'genes')
Px_sort<-(P_y[order(-P_y$ce),])
Py_sort<-(P_y[order(-P_y$ce),])
_sort<-(P_x[order(-P_x$ce),])
_sort<-(P_x[order(-P_x$ce),])
Px_sort<-(P_x[order(-P_x$ce),])
View(Py_sort)
rm(list=ls())
set.seed(200)
library('glmnet')
n=1000
p=5000
x=matrix(rnorm(n*p), nrow = n, ncol = p)
nn<-1:5000
colnames(x)<-paste('gene', nn, sep = '.')
y=apply(x[,real_p], 1, sum)+rnorm(n)
train_rows<-sample(1:n, 0.66*n)
x_train<-x[train_rows,]
x_test<-x[-train_rows,]
y_train<-y[train_rows]
y_test<-y[-train_rows]
x=matrix(rnorm(n*p), nrow = n, ncol = p)
nn<-1:5000
colnames(x)<-paste('gene', nn, sep = '.')
rm(list=ls())
set.seed(200)
library('glmnet')
n=1000
p=5000
x=matrix(rnorm(n*p), nrow = n, ncol = p)
nn<-1:5000
colnames(x)<-paste('gene', nn, sep = '.')
real_p1=c(1,3,5,7,9,11,13,15,17,19,21,23,25,27,29)
real_p2=c(21,24,25,29,30,35,40,45,60,61,68,90,99)
y1=apply(x[,real_p1], 1, sum)+rnorm(n)
y2=apply(x[,real_p2], 1, sum)+rnorm(n)
y=data.frame(y1,y2)
train_rows<-sample(1:n, 0.66*n)
x_train<-x[train_rows,]
x_test<-x[-train_rows,]
y_train<-y[train_rows,]
y_test<-y[-train_rows,]
y_train_1<-data.matrix(y_train)
y_test_1<-data.matrix(y_test)
Ridge_regg<-cv.glmnet(x_train, y_train_1, keep=T, alpha=0.5, family='mgaussian')
Pred_net<-(predict(Ridge_regg, s=Ridge_regg$lambda.1se, newx = x_test))
Pred_net<-data.matrix(Pred_net)
y_test_1<-as.vector(y_test_1)
mse_Net<-mean((Pred_net-y_test_1)^2)
mse_Net #1.21
P.coef<-(predict(Ridge_regg,type="coef"))
P_x<-as.data.frame(P.coef$y1[row.names(P.coef$y1), ])
colnames(P_x)<-'coefficients'
P_x$genes<-row.names(P_x)
P_x<-P_x[,c(2,1)]
Px_sort<-P_x[order(-P_x$coefficients),]
P_y<-as.data.frame(P.coef$y2[row.names(P.coef$y2), ])
colnames(P_y)<-'coefficients'
P_y$genes<-row.names(P_y)
P_y<-P_y[,c(2,1)]
Py_sort<-P_y[order(-P_y$coefficients),]
rm(list=ls())
rm(list=ls())
# To Reproduce the same output of simulation study
set.seed(200)
library('glmnet')
n=1000 # Number of observations (sample)
p=5000 # Number of genes
# Difine Input (x-->gene expression data)
x=matrix(rnorm(n*p), nrow = n, ncol = p)
nn<-1:5000
colnames(x)<-paste('gene', nn, sep = '.')
View(x)
real_p1=c(1,3,5,7,9,11,13,15,17,19,21,23,25,27,29)
# Index of the Genes that actually correlate with y1
real_p2=c(21,24,25,29,30,35,40,45,60,61,68,90,99)
y1=apply(x[,real_p1], 1, sum)+rnorm(n)
y2=apply(x[,real_p2], 1, sum)+rnorm(n)
y=data.frame(y1,y2)
View(y)
rm(list=ls())
set.seed(200)
# This is a simulation study to demonstrate:
# Elastic net regression on NGS data
# Clear the global environment
rm(list=ls())
# To Reproduce the same output of simulation study
set.seed(200)
# Load the required package to perform elastic net regression
library('glmnet')
n=1000 # Number of observations (sample)
p=5000 # Number of genes
# Difine Input (x-->gene expression data)
x=matrix(rnorm(n*p), nrow = n, ncol = p)
nn<-1:5000
colnames(x)<-paste('gene', nn, sep = '.')
## Define the output y1 and y2 (multi response)
# Index of the Genes that actually correlate with y1
real_p1=c(1,3,5,7,9,11,13,15,17,19,21,23,25,27,29)
# Index of the Genes that actually correlate with y1
real_p2=c(21,24,25,29,30,35,40,45,60,61,68,90,99)
y1=apply(x[,real_p1], 1, sum)+rnorm(n)
y2=apply(x[,real_p2], 1, sum)+rnorm(n)
y=data.frame(y1,y2)
### ******split data into train and test *************************************
train_rows<-sample(1:n, 0.66*n)
x_train<-x[train_rows,]
x_test<-x[-train_rows,]
y_train<-y[train_rows,]
y_test<-y[-train_rows,]
y_train_1<-data.matrix(y_train)
y_test_1<-data.matrix(y_test)
## *************Train the data with train data ***********************************
Elastic_net_regg<-cv.glmnet(x_train, y_train_1, keep=T, alpha=0.5, family='mgaussian')
## Predict the output using test data
Pred_net<-(predict(Elastic_net_regg, s=Elastic_net_regg$lambda.1se, newx = x_test))
# calculate the means square error between oredicted output and test output
Pred_net<-data.matrix(Pred_net)
y_test_1<-as.vector(y_test_1)
mse_Net<-mean((Pred_net-y_test_1)^2)
mse_Net
## ****plot test output vs predicted output ************
plot(y_test_1, Pred_net)
## ******Extract the real genes that correlate with output **********************
P.coef<-(predict(Elastic_net_regg,type="coef")) # Coeeficient associated with each genes
#Real genes that corelate with y1
P_y1<-as.data.frame(P.coef$y1[row.names(P.coef$y1), ]) # Extract coefficient for y1
colnames(P_y1)<-'coefficients'
P_y1$genes<-row.names(P_y1) # Extract gene names
P_y1<-P_y1[,c(2,1)]
P_y1_sort<-P_y1[order(-P_y1$coefficients),] # sort genes with decreassing values of coefficient
#  Here we consider coefficient associated with genes have a value >1e-1 (0.01) as real genes
sig_genes_y1<- P_y1_sort[which(P_y1_sort$coefficients > 1e-1),]
sig_genes_y1
#Real genes that corelate with y2
P_y2<-as.data.frame(P.coef$y2[row.names(P.coef$y2), ])
colnames(P_y2)<-'coefficients'
P_y2$genes<-row.names(P_y2)
P_y2<-P_y2[,c(2,1)]
P_y2_sort<-P_y2[order(-P_y2$coefficients),]
sig_genes_y2<- P_y2_sort[which(P_y2_sort$coefficients > 1e-1),]
sig_genes_y2
rm(list=ls())
setwd('D:/RNA sequencing/TimeSignature/New Project/ML_wo_norm')
# Load the required package to perform elastic net regression
library('glmnet')
## Load the data
gene.expr<-read.csv('Moller_Normalized_gene_expression_1.csv')
DLMO25<-read.csv('Moller_DLMO25_data_1.csv')
## *********  Define x (Gene expression data)**********************
x<-gene.expr[-1]
##******** Define y (Hrs after DLMO25)********************
#Conver time into angles --->   a=2*pi*time/24
DLMO25_angle<-(DLMO25[-1]%%24)*2*pi/24
# Convert angle into cartesian coordinates
y1<-sin(DLMO25_angle) # sin(a)
y2<-cos(DLMO25_angle) # cos(a)
y=data.frame(y1,y2) # y= [sin(a) cos(a)]
### ******split data into train and test *************************************
n=nrow(y)
train_rows<-sample(1:n, 0.66*n)
x_train<-x[train_rows,]
x_test<-x[-train_rows,]
x_train<-data.matrix(x_train) # Just for data handling convert it into matrix
x_test<-data.matrix(x_test)
y_train<-y[train_rows,]
y_test<-y[-train_rows,]
y_train<-data.matrix(y_train)
y_test<-data.matrix(y_test)
## *************Train the data with train data ***********************************
Ridge_regg<-cv.glmnet(x_train, y_train, keep=T, alpha=0.5, family='mgaussian')
## **********Predict the output using test data *********************************
Pred_net<-(predict(Ridge_regg, s=Ridge_regg$lambda.1se, newx = x_test))
Pred_angle<-Pred_net[,,1] # Extract the predicted angle
Pred_Time<-(atan2(Pred_angle[,1],Pred_angle[,2])%%(2*pi))*(24/(2*pi)) # convert back angle to time
y_test_Time<-(atan2(y_test[,1],y_test[,2])%%(2*pi))*(24/(2*pi))
## Find the mean square error *************************
MSE_time<-mean((Pred_Time-y_test_Time)^2)
MSE_time
## ****plot original time vs predicted time ************
plot(y_test_Time, Pred_Time)
## ******Extract the real genes that correlate with DLMO25 time **********************
P.coef<-(predict(Ridge_regg,type="coef"))
P_x<-as.data.frame(P.coef$hrs_after_DLMO25[row.names(P.coef$hrs_after_DLMO25), ])
colnames(P_x)<-'coefficients'
P_x$genes<-row.names(P_x)
P_x<-P_x[,c(2,1)]
Px_sort<-P_x[order(-P_x$coefficients),]
sig_genes<- Px_sort[which(Px_sort$coefficients > 1e-1),]
sig_gene
# Clear the global environment
rm(list=ls())
graphics.off()
setwd('C:/Users/shiju/OneDrive/Desktop/Fr Jobs/Github/Elastic net regression')
# Load the required package to perform elastic net regression
library('glmnet')
## Load the data
gene.expr<-read.csv('Moller_Normalized_gene_expression.csv')
DLMO25<-read.csv('Moller_DLMO25_data.csv')
## *********  Define x (Gene expression data)**********************
x<-gene.expr[-1]
##******** Define y (Hrs after DLMO25)********************
#Conver time into angles --->   a=2*pi*time/24
DLMO25_angle<-(DLMO25[-1]%%24)*2*pi/24
# Convert angle into cartesian coordinates
y1<-sin(DLMO25_angle) # sin(a)
y2<-cos(DLMO25_angle) # cos(a)
y=data.frame(y1,y2) # y= [sin(a) cos(a)]
### ******split data into train and test *************************************
n=nrow(y)
train_rows<-sample(1:n, 0.66*n)
x_train<-x[train_rows,]
x_test<-x[-train_rows,]
x_train<-data.matrix(x_train) # Just for data handling convert it into matrix
x_test<-data.matrix(x_test)
y_train<-y[train_rows,]
y_test<-y[-train_rows,]
y_train<-data.matrix(y_train)
y_test<-data.matrix(y_test)
## *************Train the data with train data ***********************************
Ridge_regg<-cv.glmnet(x_train, y_train, keep=T, alpha=0.5, family='mgaussian')
## **********Predict the output using test data *********************************
Pred_net<-(predict(Ridge_regg, s=Ridge_regg$lambda.1se, newx = x_test))
Pred_angle<-Pred_net[,,1] # Extract the predicted angle
Pred_Time<-(atan2(Pred_angle[,1],Pred_angle[,2])%%(2*pi))*(24/(2*pi)) # convert back angle to time
y_test_Time<-(atan2(y_test[,1],y_test[,2])%%(2*pi))*(24/(2*pi))
## Find the mean square error *************************
MSE_time<-mean((Pred_Time-y_test_Time)^2)
MSE_time
## ****plot original time vs predicted time ************
plot(y_test_Time, Pred_Time)
## ******Extract the real genes that correlate with DLMO25 time **********************
P.coef<-(predict(Ridge_regg,type="coef"))
P_x<-as.data.frame(P.coef$hrs_after_DLMO25[row.names(P.coef$hrs_after_DLMO25), ])
colnames(P_x)<-'coefficients'
P_x$genes<-row.names(P_x)
P_x<-P_x[,c(2,1)]
Px_sort<-P_x[order(-P_x$coefficients),]
sig_genes<- Px_sort[which(Px_sort$coefficients > 1e-1),]
sig_gene
ig_genes
sig_genes
sig_genes<- Px_sort[which(Px_sort$coefficients > 1e-2),]
sig_genes
rm(list=ls())
set.seed(200)
setwd('C:/Users/shiju/OneDrive/Desktop/Fr Jobs/Github/Elastic net regression')
# Load the required package to perform elastic net regression
library('glmnet')
## Load the data
gene.expr<-read.csv('Moller_Normalized_gene_expression.csv')
DLMO25<-read.csv('Moller_DLMO25_data.csv')
## *********  Define x (Gene expression data)**********************
x<-gene.expr[-1]
##******** Define y (Hrs after DLMO25)********************
#Conver time into angles --->   a=2*pi*time/24
DLMO25_angle<-(DLMO25[-1]%%24)*2*pi/24
# Convert angle into cartesian coordinates
y1<-sin(DLMO25_angle) # sin(a)
y2<-cos(DLMO25_angle) # cos(a)
y=data.frame(y1,y2) # y= [sin(a) cos(a)]
### ******split data into train and test *************************************
n=nrow(y)
train_rows<-sample(1:n, 0.66*n)
x_train<-x[train_rows,]
x_test<-x[-train_rows,]
x_train<-data.matrix(x_train) # Just for data handling convert it into matrix
x_test<-data.matrix(x_test)
y_train<-y[train_rows,]
y_test<-y[-train_rows,]
y_train<-data.matrix(y_train)
y_test<-data.matrix(y_test)
## *************Train the data with train data ***********************************
Ridge_regg<-cv.glmnet(x_train, y_train, keep=T, alpha=0.5, family='mgaussian')
## **********Predict the output using test data *********************************
Pred_net<-(predict(Ridge_regg, s=Ridge_regg$lambda.1se, newx = x_test))
Pred_angle<-Pred_net[,,1] # Extract the predicted angle
Pred_Time<-(atan2(Pred_angle[,1],Pred_angle[,2])%%(2*pi))*(24/(2*pi)) # convert back angle to time
y_test_Time<-(atan2(y_test[,1],y_test[,2])%%(2*pi))*(24/(2*pi))
## Find the mean square error *************************
MSE_time<-mean((Pred_Time-y_test_Time)^2)
MSE_time
## ****plot original time vs predicted time ************
plot(y_test_Time, Pred_Time)
## ******Extract the real genes that correlate with DLMO25 time **********************
P.coef<-(predict(Ridge_regg,type="coef"))
P_x<-as.data.frame(P.coef$hrs_after_DLMO25[row.names(P.coef$hrs_after_DLMO25), ])
colnames(P_x)<-'coefficients'
P_x$genes<-row.names(P_x)
P_x<-P_x[,c(2,1)]
Px_sort<-P_x[order(-P_x$coefficients),]
sig_genes<- Px_sort[which(Px_sort$coefficients > 1e-1),]
sig_genes
rm(list=ls())
set.seed(200)
rm(list=ls())
set.seed(200)
# set the path where code and data stored. Please change this line according to your local machine path
setwd('D:/Github_files/Machine-Learning-in-Bioinformatics')
# Load the required package to perform elastic net regression
library('glmnet')
## Load the data
gene.expr<-read.csv('Moller_Normalized_gene_expression.csv')
DLMO25<-read.csv('Moller_DLMO25_data.csv')
rm(list=ls())
set.seed(200)
# Load the required package to perform elastic net regression
library('glmnet')
n=1000 # Number of observations (sample)
p=5000 # Number of genes
# Difine Input (x-->gene expression data)
x=matrix(rnorm(n*p), nrow = n, ncol = p)
nn<-1:5000
colnames(x)<-paste('gene', nn, sep = '.')
## Define the output y1 and y2 (multi response)
# Index of the Genes that actually correlate with y1
real_p1=c(1,3,5,7,9,11,13,15,17,19,21,23,25,27,29)
# Index of the Genes that actually correlate with y1
real_p2=c(21,24,25,29,30,35,40,45,60,61,68,90,99)
y1=apply(x[,real_p1], 1, sum)+rnorm(n)
y2=apply(x[,real_p2], 1, sum)+rnorm(n)
y=data.frame(y1,y2)
### ******split data into train and test *************************************
train_rows<-sample(1:n, 0.66*n)
x_train<-x[train_rows,]
x_test<-x[-train_rows,]
y_train<-y[train_rows,]
y_test<-y[-train_rows,]
y_train_1<-data.matrix(y_train)
y_test_1<-data.matrix(y_test)
## *************Train the data with train data ***********************************
Elastic_net_regg<-cv.glmnet(x_train, y_train_1, keep=T, alpha=0.5, family='mgaussian')
## Predict the output using test data
Pred_net<-(predict(Elastic_net_regg, s=Elastic_net_regg$lambda.1se, newx = x_test))
# calculate the means square error between predicted output and test output
Pred_net<-data.matrix(Pred_net)
y_test_1<-as.vector(y_test_1)
mse_Net<-mean((Pred_net-y_test_1)^2)
mse_Net
## ****plot test output vs predicted output ************
plot(y_test_1, Pred_net)
# Clear the global environment
rm(list=ls())
set.seed(200)
# set the path where code and data stored. Please change this line according to your local machine path
setwd('D:/Github_files/Machine-Learning-in-Bioinformatics')
# Load the required package to perform elastic net regression
library('glmnet')
## Load the data
gene.expr<-read.csv('Moller_Normalized_gene_expression.csv')
DLMO25<-read.csv('Moller_DLMO25_data.csv')
## *********  Define x (Gene expression data)**********************
x<-gene.expr[-1]
##******** Define y (Hrs after DLMO25)********************
#Conver time into angles --->   a=2*pi*time/24
DLMO25_angle<-(DLMO25[-1]%%24)*2*pi/24
# Convert angle into cartesian coordinates
y1<-sin(DLMO25_angle) # sin(a)
y2<-cos(DLMO25_angle) # cos(a)
y=data.frame(y1,y2) # y= [sin(a) cos(a)]
### ******split data into train and test *************************************
n=nrow(y)
train_rows<-sample(1:n, 0.66*n)
x_train<-x[train_rows,]
x_test<-x[-train_rows,]
x_train<-data.matrix(x_train) # Just for data handling convert it into matrix
x_test<-data.matrix(x_test)
y_train<-y[train_rows,]
y_test<-y[-train_rows,]
y_train<-data.matrix(y_train)
y_test<-data.matrix(y_test)
## *************Train the data with train data ***********************************
Ridge_regg<-cv.glmnet(x_train, y_train, keep=T, alpha=0.5, family='mgaussian')
## **********Predict the output using test data *********************************
Pred_net<-(predict(Ridge_regg, s=Ridge_regg$lambda.1se, newx = x_test))
Pred_angle<-Pred_net[,,1] # Extract the predicted angle
Pred_Time<-(atan2(Pred_angle[,1],Pred_angle[,2])%%(2*pi))*(24/(2*pi)) # convert back angle to time
y_test_Time<-(atan2(y_test[,1],y_test[,2])%%(2*pi))*(24/(2*pi))
## Find the mean square error *************************
MSE_time<-mean((Pred_Time-y_test_Time)^2)
MSE_time
## ****plot original time vs predicted time ************
plot(y_test_Time, Pred_Time)
## ******Extract the real genes that correlate with DLMO25 time **********************
P.coef<-(predict(Ridge_regg,type="coef"))
P_x<-as.data.frame(P.coef$hrs_after_DLMO25[row.names(P.coef$hrs_after_DLMO25), ])
colnames(P_x)<-'coefficients'
P_x$genes<-row.names(P_x)
P_x<-P_x[,c(2,1)]
Px_sort<-P_x[order(-P_x$coefficients),]
sig_genes<- Px_sort[which(Px_sort$coefficients > 1e-1),]
sig_genes
